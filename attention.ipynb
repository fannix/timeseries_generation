{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2TxreSED2maeKDXJu53/+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fannix/timeseries_generation/blob/master/attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWclGfe-E4qQ",
        "colab_type": "code",
        "outputId": "7880d87c-6e10-4a2e-980e-6f31b166eebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import torch\n",
        "batch_size = 5\n",
        "nb_digits = 10\n",
        "y = torch.LongTensor(batch_size,1).random_() % nb_digits\n",
        "y\n",
        "y_onehot = torch.FloatTensor(batch_size, nb_digits)\n",
        "y_onehot.zero_()\n",
        "y_onehot.scatter_(1, y, 1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq-knOM4rWPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU7xzLWwqq9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input, hc):\n",
        "    output = self.embedding(input)\n",
        "    output = torch.relu(output)\n",
        "    output, (hidden, cell) = self.lstm(output, hc)\n",
        "    #print(output.shape)\n",
        "    output = self.out(output)\n",
        "    return output, (hidden, cell)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    return (torch.zeros(1, batch_size, self.hidden_size, device=device), \n",
        "            torch.zeros(1, batch_size, self.hidden_size, device=device))\n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "  def forward(self, input, hc):\n",
        "    embedded = self.embedding(input)\n",
        "    output = embedded\n",
        "    output, (hidden, cell) = self.lstm(output, hc)\n",
        "    return output, (hidden, cell)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
        "            torch.zeros(1, batch_size, self.hidden_size, device=device))\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.encoder = EncoderRNN(input_size, hidden_size)\n",
        "    self.decoder = DecoderRNN(hidden_size, input_size)\n",
        "  \n",
        "  def forward(self, input, expected = None):\n",
        "    batch_size = input.shape[0]\n",
        "    h0, c0 = self.encoder.init_hidden(batch_size)\n",
        "    encode_output, (encode_hidden, encode_cell) = self.encoder(input, (h0, c0))\n",
        "\n",
        "    inp = torch.zeros(batch_size, dtype=torch.long, device=device)\n",
        "    inp = inp.view(batch_size, 1)\n",
        "    h, c = encode_hidden, encode_cell\n",
        "\n",
        "    #print(inp.shape)\n",
        "    output_list = []\n",
        "    while True:\n",
        "      if expected == None:\n",
        "        out, (h, c) = self.decoder(inp, (h, c))\n",
        "      # teacher forcing\n",
        "      else:\n",
        "        pass\n",
        "      output_list.append(out.squeeze(1))\n",
        "      if len(output_list) == input.shape[1]:\n",
        "        break\n",
        "    # print(output_list[0].shape)\n",
        "    return torch.stack(output_list, 2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk0GKtWAf9IM",
        "colab_type": "text"
      },
      "source": [
        "Attention LSTM Seq2Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5zk7gq6Q6qD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xeh1MYIISvng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "c9796390-0dc9-4771-80c7-1dff7b8c7f1d"
      },
      "source": [
        "import torch\n",
        "\n",
        "def mask_3d(inputs, seq_len, mask_value=0.):\n",
        "    \"\"\"\n",
        "    Use the mask_value to make a 3d or 2d tensor\n",
        "    inputs: tensor. N*T*D\n",
        "    seq_len: N. length of valid seq\n",
        "    \"\"\"\n",
        "    batches = inputs.size()[0]\n",
        "    assert batches == len(seq_len)\n",
        "    max_idx = max(seq_len)\n",
        "    for n, idx in enumerate(seq_len):\n",
        "        if idx <= max_idx.item():\n",
        "            if len(inputs.size()) == 3:\n",
        "                inputs[n, idx.int():, :] = mask_value\n",
        "            else:\n",
        "                assert len(inputs.size()) == 2, \"The size of inputs must be 2 or 3, received {}\".format(inputs.size())\n",
        "                inputs[n, idx.int():] = mask_value\n",
        "    return inputs\n",
        "\n",
        "input = torch.randn(3, 4)\n",
        "seq_len = torch.LongTensor([1, 2, 3])\n",
        "print(seq_len)\n",
        "mask_3d(input, seq_len)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4719,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.2437, -0.7672,  0.0000,  0.0000],\n",
              "        [ 1.0179, -0.5958,  1.2337,  0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nu1hf3dQMZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_collate(batch, values=(0, 0), dim=0):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        batch - list of (tensor, label)\n",
        "    reutrn:\n",
        "        xs - a tensor of all examples in 'batch' after padding\n",
        "        ys - a LongTensor of all labels in batch\n",
        "        ws - a tensor of sequence lengths\n",
        "    \"\"\"\n",
        "\n",
        "    sequence_lengths = torch.Tensor([int(x[0].shape[dim]) for x in batch])\n",
        "    sequence_lengths, xids = sequence_lengths.sort(descending=True)\n",
        "    target_lengths = torch.Tensor([int(x[1].shape[dim]) for x in batch])\n",
        "    target_lengths, yids = target_lengths.sort(descending=True)\n",
        "    batch_x, batch_y = list(zip(*batch))\n",
        "    batch_x = torch.nn.utils.rnn.pad_sequence(batch_x, batch_first=True, padding_value=values[0])\n",
        "    batch_y = torch.nn.utils.rnn.pad_sequence(batch_y, batch_first=True, padding_value=values[1])\n",
        "\n",
        "    # stack all\n",
        "\n",
        "    xs = batch_x[xids]\n",
        "    ys = batch_y[yids]\n",
        "    return xs, ys, sequence_lengths.int(), target_lengths.int()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvvC22fD490C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6e38853-06a6-417a-8d70-4e8272cc5d6c"
      },
      "source": [
        "zipped = [(\"a\", 1), (\"b\", 2)]\n",
        "\n",
        "unzipped_object = zip(*zipped)\n",
        "\n",
        "unzipped_list = list(unzipped_object)\n",
        "print(unzipped_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('a', 'b'), (1, 2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWfczEhHRYye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "3df15b49-44da-4bfe-a469-4320555c3998"
      },
      "source": [
        "# https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch\n",
        "import torch\n",
        "a = [torch.tensor([1,2,3]), torch.tensor([3, 4, 5, 6])]\n",
        "b = torch.nn.utils.rnn.pad_sequence(a, batch_first=True)\n",
        "print(a)\n",
        "print(b)\n",
        "c = torch.nn.utils.rnn.pack_padded_sequence(b, batch_first=True, lengths=[3,4], enforce_sorted=False)\n",
        "torch.nn.utils.rnn.pad_packed_sequence(c)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([1, 2, 3]), tensor([3, 4, 5, 6])]\n",
            "tensor([[1, 2, 3, 0],\n",
            "        [3, 4, 5, 6]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 3],\n",
              "         [2, 4],\n",
              "         [3, 5],\n",
              "         [0, 6]]), tensor([3, 4]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGOZD16V9TAU",
        "colab_type": "code",
        "outputId": "a01950ed-93cf-4f47-8c87-0e87d38eccae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torch.utils import data\n",
        "from random import choice, randrange\n",
        "import numpy as np\n",
        "class ReverseDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Inspired from https://talbaumel.github.io/blog/attention/\n",
        "    https://towardsdatascience.com/attention-seq2seq-with-pytorch-learning-to-invert-a-sequence-34faf4133e53\n",
        "    \"\"\"\n",
        "    def __init__(self, min_length=5, max_length=20, type='train'):\n",
        "        self.SOS = \"<s>\"  # id 1\n",
        "        self.EOS = \"</s>\" # id 2, id of mask will be 0\n",
        "        self.characters = list(\"abcd\")\n",
        "        self.int2char = list(self.characters)\n",
        "        self.char2int = {c: i+3 for i, c in enumerate(self.characters)}\n",
        "        self.VOCAB_SIZE = len(self.characters)\n",
        "        self.min_length = min_length\n",
        "        self.max_length = max_length\n",
        "        if type=='train':\n",
        "            self.dataset = [self._sample() for _ in range(3000)]\n",
        "        else:\n",
        "            self.dataset = [self._sample() for _ in range(300)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.dataset[item]\n",
        "\n",
        "    def _sample(self):\n",
        "        if self.min_length != self.max_length:\n",
        "            random_length = randrange(self.min_length, self.max_length)# Pick a random length\n",
        "        else:\n",
        "            random_length = self.min_length\n",
        "        random_char_list = [choice(self.characters[:-1]) for _ in range(random_length)]  # Pick random chars\n",
        "        random_string = ''.join(random_char_list)\n",
        "        a = torch.LongTensor([self.char2int.get(x) for x in random_string] + [2])\n",
        "        b = torch.LongTensor([self.char2int.get(x) for x in random_string[::-1]] + [2]) # Return the random string and its reverse\n",
        "        #x = np.zeros((random_length, self.VOCAB_SIZE))\n",
        "        #x[np.arange(random_length), a-2] = 1\n",
        "        return a, b\n",
        "\n",
        "reverse_dataset = ReverseDataset(4, 4)\n",
        "reverse_dataset[0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([4, 3, 3, 5, 2]), tensor([5, 3, 3, 4, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8EV27NZUuR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5-o01AZGf6kv",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import math\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class AttenEncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "  def forward(self, input, hc):\n",
        "    embedded = self.embedding(input)\n",
        "    output = embedded\n",
        "    output, (hidden, cell) = self.lstm(output, hc)\n",
        "    return output, (hidden, cell)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n",
        "            torch.zeros(1, batch_size, self.hidden_size, device=device))\n",
        "\n",
        "class AttenDecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.combine = nn.Linear(2 * hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, input, hc, encode_out):\n",
        "    embed = self.embedding(input)\n",
        "    attn = attention(embed, encode_out, encode_out)\n",
        "    comb = self.combine(torch.cat([embed, attn[0]], -1))\n",
        "    output = torch.relu(comb)\n",
        "    output, (hidden, cell) = self.lstm(output, hc)\n",
        "    #print(output.shape)\n",
        "    output = self.out(output)\n",
        "    return output, (hidden, cell)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    return (torch.zeros(1, batch_size, self.hidden_size, device=device), \n",
        "            torch.zeros(1, batch_size, self.hidden_size, device=device))\n",
        "\n",
        "\n",
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"\"\"Compute 'Scaled Dot Product Attention\n",
        "    query: N x 1 x D\n",
        "    key: N x T x D\n",
        "    value: N x T x D. key and value are the same. query, key and value are the same for self attention\n",
        "    scores: N x 1 x T\n",
        "    p_attn: N x 1 x T\n",
        "    result: N x 1 x D\n",
        "    \n",
        "    \"\"\"\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
        "             / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    p_attn = torch.nn.functional.softmax(scores, dim = -1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn\n",
        "\n",
        "class AttenSeq2Seq(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.encoder = AttenEncoderRNN(input_size, hidden_size)\n",
        "    self.decoder = AttenDecoderRNN(hidden_size, input_size)\n",
        "  \n",
        "  def forward(self, input, expected = None):\n",
        "    batch_size = input.shape[0]\n",
        "    h0, c0 = self.encoder.init_hidden(batch_size)\n",
        "    encode_output, (encode_hidden, encode_cell) = self.encoder(input, (h0, c0))\n",
        "    # 0 is the start_symbol\n",
        "    inp = torch.zeros(batch_size, dtype=torch.long, device=device)\n",
        "    inp = inp.view(batch_size, 1)\n",
        "    h, c = encode_hidden, encode_cell\n",
        "    #print(inp.shape)\n",
        "    output_list = []\n",
        "    while True:\n",
        "      if expected == None:\n",
        "        out, (h, c) = self.decoder(inp, (h, c), encode_output)\n",
        "      # teacher forcing\n",
        "      else:\n",
        "        pass\n",
        "      output_list.append(out.squeeze(1))\n",
        "      if len(output_list) == input.shape[1]:\n",
        "        break\n",
        "    # print(output_list[0].shape)\n",
        "    return torch.stack(output_list, 2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bO2NLMp9XM3",
        "colab_type": "code",
        "outputId": "75ee34ac-91c4-430b-96e0-950a043ff9ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "reverse_dataset = ReverseDataset(3, 15)\n",
        "\n",
        "loader = DataLoader(reverse_dataset, 8, collate_fn=pad_collate)\n",
        "\n",
        "model = AttenSeq2Seq(len(reverse_dataset.char2int) + 3, 128).to(device)\n",
        "\n",
        "criterion = torch.nn.functional.cross_entropy\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "for epoch in range(10):\n",
        "  sum_criterion = 0\n",
        "  n_instance = 0\n",
        "  for x, y, _, _ in loader:\n",
        "    n_instance += x.shape[0]\n",
        "    optimizer.zero_grad()\n",
        "    res = model(x.to(device))\n",
        "    loss = criterion(res, y.to(device), ignore_index=0)\n",
        "    loss.backward()\n",
        "    sum_criterion += loss.item()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'{epoch}: {sum_criterion/n_instance}')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 0.106606081366539\n",
            "1: 0.050170929918686547\n",
            "2: 0.03474776198714972\n",
            "3: 0.028429493901630243\n",
            "4: 0.02339400139761468\n",
            "5: 0.01947456406770895\n",
            "6: 0.016559849640354514\n",
            "7: 0.014721399666431049\n",
            "8: 0.012717607431346551\n",
            "9: 0.011861645702971145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d9BRd4pSA4M",
        "colab_type": "code",
        "outputId": "3dc41b58-33b8-4f45-b121-8dedab97e686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "print(y)\n",
        "\n",
        "res = model(x.to(device))\n",
        "\n",
        "predict = res.argmax(dim=1)\n",
        "print(predict)\n",
        "y.masked_fill_(y==0, 2)\n",
        "\n",
        "print(torch.sum(predict == y.to(device)) / float(res.shape[0] * res.shape[2]))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5, 4, 3, 5, 3, 3, 4, 3, 4, 4, 4, 4, 4, 5, 2],\n",
            "        [5, 4, 4, 5, 5, 4, 5, 3, 4, 5, 3, 3, 3, 3, 2],\n",
            "        [5, 3, 3, 4, 3, 5, 4, 3, 4, 5, 4, 2, 0, 0, 0],\n",
            "        [3, 3, 3, 4, 4, 3, 4, 5, 4, 4, 4, 2, 0, 0, 0],\n",
            "        [3, 3, 4, 3, 5, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [3, 3, 5, 5, 4, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [5, 4, 5, 3, 5, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [3, 4, 4, 5, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[5, 4, 3, 5, 3, 3, 4, 3, 4, 4, 4, 4, 4, 5, 2],\n",
            "        [5, 4, 4, 5, 5, 4, 5, 3, 4, 5, 3, 3, 3, 3, 2],\n",
            "        [5, 3, 3, 4, 3, 5, 4, 3, 4, 5, 4, 2, 2, 2, 2],\n",
            "        [3, 3, 3, 4, 4, 3, 4, 5, 4, 4, 4, 2, 2, 2, 2],\n",
            "        [3, 3, 4, 3, 5, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2],\n",
            "        [3, 3, 5, 5, 4, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2],\n",
            "        [5, 4, 5, 3, 5, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
            "        [3, 4, 4, 5, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7YM2PSETM1B",
        "colab_type": "code",
        "outputId": "e94844fc-fa47-4a60-bc36-b11e4deb74ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a = torch.LongTensor([[3, 3, 4, 5, 2], [5, 4, 3, 3, 2]]).to(device)\n",
        "model(a).argmax(1)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5, 4, 3, 3, 2],\n",
              "        [3, 3, 4, 5, 2]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_1e6i9IwZTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66437302-9e52-4ac7-f172-bbbd08d9ca7c"
      },
      "source": [
        "reverse_dataset_val = ReverseDataset(3, 10, type=\"test\")\n",
        "val_loader = DataLoader(reverse_dataset_val, 1, collate_fn=pad_collate)\n",
        "with torch.no_grad():\n",
        "  ncorrect = 0\n",
        "  nwrong = 0\n",
        "  for x, y, _, _ in val_loader:\n",
        "    y.masked_fill_(y==0, 2)\n",
        "    predict = model(x.to(device)).argmax(1)\n",
        "    if torch.equal(y.to(device), predict):\n",
        "      ncorrect += 1\n",
        "    else:\n",
        "      nwrong += 1\n",
        "print(f'{ncorrect}, {nwrong}')\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "288, 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUZa5cpxTF8s",
        "colab_type": "text"
      },
      "source": [
        "# Test PeriodicDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtSH_ivjqXHn",
        "colab_type": "code",
        "outputId": "91514a23-48b6-46b2-87cb-7b8fef361921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from random import choice, randrange\n",
        "\n",
        "class PeriodicSeriesDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, sequence, num, min_length=5, max_length=15):\n",
        "    \n",
        "    self.sequence = sequence\n",
        "    self.start_symbol = \"<s>\"\n",
        "    self.end_symbol = \"</s>\"\n",
        "    self.min_length = min_length\n",
        "    self.max_length = max_length\n",
        "\n",
        "    self.x = []\n",
        "    self.y = []\n",
        "    self.id2word = {i+3: w for (i, w) in enumerate(sequence)}\n",
        "    self.id2word[0] = \"\" #mask\n",
        "    self.id2word[1] = self.start_symbol\n",
        "    self.id2word[2] = self.end_symbol\n",
        "    self.word2id = {w: i for (i, w) in self.id2word.items()}\n",
        "    seq2id = np.array([self.word2id[w] for w in sequence])\n",
        "    print(sequence)\n",
        "\n",
        "    for i in range(num):\n",
        "      xi, yi = self._sample(self.min_length, self.max_length)\n",
        "      xi = torch.LongTensor([self.word2id[e] for e in xi] + [2])\n",
        "      yi = torch.LongTensor([self.word2id[e] for e in yi] + [2])\n",
        "\n",
        "      self.x.append(xi)\n",
        "      self.y.append(yi)\n",
        "\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  \n",
        "  def _sample(self, min_length, max_length):\n",
        "    random_length = randrange(min_length, max_length)                        # Pick a random length\n",
        "    random_char_list = [choice(self.sequence) for _ in range(random_length)]  # Pick random chars\n",
        "    random_string = ''.join(random_char_list) \n",
        "    return random_string, random_string[-1] + random_string[0:-1]  # Return the random string and its shift\n",
        "\n",
        "  def onehot_seq(self, word_seq):\n",
        "    num_seq = [self.word2id[w] for w in word_seq]\n",
        "    return self.onehot_num(num_seq)\n",
        "  \n",
        "  def onehot_num(self, num_seq):\n",
        "    y = torch.LongTensor(num_seq).view(-1, 1)\n",
        "    onehot = torch.FloatTensor(len(num_seq), len(self.word2id))\n",
        "    onehot.zero_()\n",
        "    onehot.scatter_(1, y, 1)\n",
        "    return onehot\n",
        "  \n",
        "  def onecold_num(self, tensor):\n",
        "    dim_n = tensor.shape[0]\n",
        "    dim_c = tensor.shape[1]\n",
        "    onecold = tensor.argmax(dim=1)\n",
        "    return onecold\n",
        "\n",
        "  def onecold_seq(self, tensor):\n",
        "    onecold = self.onecold_num(tensor)\n",
        "    print(onecold)\n",
        "    return [self.id2word[i.item()] for i in onecold]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return  self.x[index], self.y[index]\n",
        "\n",
        "import string\n",
        "sequence = list(string.ascii_letters[:6])\n",
        "pseries = PeriodicSeriesDataset(sequence, 10)\n",
        "for i in range(len(pseries)):\n",
        "  print(pseries[i])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f']\n",
            "(tensor([3, 4, 4, 7, 4, 4, 2]), tensor([4, 3, 4, 4, 7, 4, 2]))\n",
            "(tensor([4, 5, 7, 7, 7, 8, 8, 2]), tensor([8, 4, 5, 7, 7, 7, 8, 2]))\n",
            "(tensor([5, 4, 7, 3, 5, 6, 5, 8, 3, 5, 2]), tensor([5, 5, 4, 7, 3, 5, 6, 5, 8, 3, 2]))\n",
            "(tensor([4, 7, 3, 3, 5, 8, 2]), tensor([8, 4, 7, 3, 3, 5, 2]))\n",
            "(tensor([3, 5, 7, 5, 8, 3, 4, 7, 8, 4, 2]), tensor([4, 3, 5, 7, 5, 8, 3, 4, 7, 8, 2]))\n",
            "(tensor([5, 5, 8, 8, 5, 4, 4, 3, 2]), tensor([3, 5, 5, 8, 8, 5, 4, 4, 2]))\n",
            "(tensor([5, 4, 3, 8, 8, 7, 4, 4, 2]), tensor([4, 5, 4, 3, 8, 8, 7, 4, 2]))\n",
            "(tensor([8, 6, 3, 3, 8, 3, 6, 3, 5, 5, 8, 6, 7, 6, 2]), tensor([6, 8, 6, 3, 3, 8, 3, 6, 3, 5, 5, 8, 6, 7, 2]))\n",
            "(tensor([7, 5, 6, 6, 7, 6, 6, 3, 2]), tensor([3, 7, 5, 6, 6, 7, 6, 6, 2]))\n",
            "(tensor([7, 4, 5, 7, 7, 2]), tensor([7, 7, 4, 5, 7, 2]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3vJ7onlNrkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence = list(string.ascii_letters[:4])\n",
        "pseries = PeriodicSeriesDataset(sequence, 3000, 5, 25)\n",
        "loader = torch.utils.data.DataLoader(pseries, 8, collate_fn=pad_collate)\n",
        "\n",
        "model = Seq2Seq(len(pseries.word2id), 20).to(device)\n",
        "\n",
        "criterion = torch.nn.functional.cross_entropy\n",
        "optimizer = torch.optim.RMSprop(model.parameters())\n",
        "for epoch in range(10):\n",
        "  sum_criterion = 0\n",
        "  n_instance = 0\n",
        "  for x, y in loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    n_instance += x.shape[0]\n",
        "    optimizer.zero_grad()\n",
        "    res = model(x.to(device))\n",
        "    loss = criterion(res, y, ignore_index=0)\n",
        "    loss.backward()\n",
        "    sum_criterion += loss.item()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'{epoch}: {sum_criterion/n_instance}')\n",
        "  #print(res.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAFlJO6kP2TE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e8b10cf6-de09-44ff-ed56-aaece5406db7"
      },
      "source": [
        "periodic_dataset_val = PeriodicSeriesDataset(list(string.ascii_letters[:4]), 300, 5, 10)\n",
        "val_loader = DataLoader(periodic_dataset_val, 1)\n",
        "with torch.no_grad():\n",
        "  ncorrect = 0\n",
        "  nwrong = 0\n",
        "  for x, y in val_loader:\n",
        "    predict = model(x.to(device)).argmax(1)\n",
        "    if torch.equal(y, predict):\n",
        "      ncorrect += 1\n",
        "    else:\n",
        "      nwrong += 1\n",
        "print(f'{ncorrect}, {nwrong}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'b', 'c', 'd']\n",
            "37, 263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW2zDyJjgJgf",
        "colab_type": "code",
        "outputId": "e77fa746-6376-46ad-bfdb-cdd5abfbd50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "sequence = list(string.ascii_letters[:4])\n",
        "pseries = PeriodicSeriesDataset(sequence, 30000, 5, 15)\n",
        "loader = torch.utils.data.DataLoader(pseries, 8, collate_fn=pad_collate)\n",
        "\n",
        "model = AttenSeq2Seq(len(pseries.word2id), 128).to(device)\n",
        "\n",
        "criterion = torch.nn.functional.cross_entropy\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "for epoch in range(10):\n",
        "  sum_criterion = 0\n",
        "  n_instance = 0\n",
        "  for x, y, _, _ in loader:\n",
        "    n_instance += x.shape[0]\n",
        "    optimizer.zero_grad()\n",
        "    res = model(x.to(device))\n",
        "    loss = criterion(res, y.to(device), ignore_index=0)\n",
        "    loss.backward()\n",
        "    sum_criterion += loss.item()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'{epoch}: {sum_criterion/n_instance}')\n",
        "  #print(res.shape)\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'b', 'c', 'd']\n",
            "0: 0.05647364083528519\n",
            "1: 0.015494815326031919\n",
            "2: 0.008653825540990026\n",
            "3: 0.0061585602746413014\n",
            "4: 0.004265977233648057\n",
            "5: 0.0037410321544952847\n",
            "6: 0.004059121511562019\n",
            "7: 0.0023891238057689407\n",
            "8: 0.0021015634532313317\n",
            "9: 0.0025635717473411813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B35Gr8lPwir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e4001c9-2300-4390-8e17-5c4a897362ed"
      },
      "source": [
        "n_instance"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82YIxVarOubJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "92bfb1f9-8b5f-4b1a-9c95-9ee9a6e22da1"
      },
      "source": [
        "print(x, y)\n",
        "\n",
        "res = model(x.to(device))\n",
        "\n",
        "predict = res.argmax(dim=1)\n",
        "print(predict)\n",
        "y.masked_fill_(y==0, 2)\n",
        "\n",
        "print(torch.sum(predict == y.to(device)) / float(res.shape[0] * res.shape[2]))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6, 3, 4, 6, 6, 5, 3, 4, 3, 3, 4, 3, 6, 5, 2],\n",
            "        [6, 3, 5, 3, 4, 6, 5, 5, 6, 6, 3, 2, 0, 0, 0],\n",
            "        [5, 6, 4, 4, 4, 4, 4, 3, 5, 6, 5, 2, 0, 0, 0],\n",
            "        [4, 4, 4, 4, 5, 6, 6, 6, 6, 2, 0, 0, 0, 0, 0],\n",
            "        [3, 6, 6, 3, 5, 3, 6, 3, 4, 2, 0, 0, 0, 0, 0],\n",
            "        [5, 3, 6, 4, 6, 4, 3, 6, 2, 0, 0, 0, 0, 0, 0],\n",
            "        [5, 4, 4, 3, 5, 4, 4, 2, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [6, 3, 3, 3, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]]) tensor([[5, 6, 3, 4, 6, 6, 5, 3, 4, 3, 3, 4, 3, 6, 2],\n",
            "        [3, 6, 3, 5, 3, 4, 6, 5, 5, 6, 6, 2, 0, 0, 0],\n",
            "        [5, 5, 6, 4, 4, 4, 4, 4, 3, 5, 6, 2, 0, 0, 0],\n",
            "        [6, 4, 4, 4, 4, 5, 6, 6, 6, 2, 0, 0, 0, 0, 0],\n",
            "        [4, 3, 6, 6, 3, 5, 3, 6, 3, 2, 0, 0, 0, 0, 0],\n",
            "        [6, 5, 3, 6, 4, 6, 4, 3, 2, 0, 0, 0, 0, 0, 0],\n",
            "        [4, 5, 4, 4, 3, 5, 4, 2, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [4, 6, 3, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[5, 6, 3, 4, 6, 6, 5, 3, 4, 3, 3, 4, 3, 6, 2],\n",
            "        [3, 6, 3, 5, 3, 4, 6, 5, 5, 6, 6, 2, 2, 2, 2],\n",
            "        [5, 5, 6, 4, 4, 4, 4, 4, 3, 5, 6, 2, 2, 2, 2],\n",
            "        [6, 4, 4, 4, 4, 5, 6, 6, 6, 2, 2, 2, 2, 3, 2],\n",
            "        [4, 3, 6, 6, 3, 5, 3, 6, 3, 2, 2, 2, 2, 2, 2],\n",
            "        [6, 5, 3, 6, 4, 6, 4, 3, 2, 2, 2, 2, 2, 2, 2],\n",
            "        [4, 5, 4, 4, 3, 5, 4, 2, 2, 2, 2, 2, 2, 2, 2],\n",
            "        [4, 6, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2]])\n",
            "tensor(0.9833)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jusInF-D5VkK",
        "colab_type": "code",
        "outputId": "e0909a91-4df6-44d8-ecf7-026a26e63047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model(\n",
        "    torch.LongTensor(\n",
        "    [[3, 3, 4, 5, 2],\n",
        "     [3, 4, 5, 6, 2]\n",
        "     ]).to(device)\n",
        ").argmax(dim=1)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5, 3, 3, 4, 2],\n",
              "        [6, 3, 4, 5, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JZz7L1nP7kU",
        "colab_type": "code",
        "outputId": "a1d4a186-0b64-40dd-deef-a8c05312736e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model(\n",
        "    torch.LongTensor(\n",
        "    [[3, 5, 6, 3, 6, 4, 2],\n",
        "     [5, 6, 3, 3, 6, 4, 2]\n",
        "     ]).to(device)\n",
        ").argmax(dim=1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4, 3, 5, 6, 3, 6, 2],\n",
              "        [4, 5, 6, 3, 3, 6, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoRygRGJ8_If",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2b236a2e-cf19-4447-f4f9-d7da96cedea8"
      },
      "source": [
        "periodic_dataset_val = PeriodicSeriesDataset(list(string.ascii_letters[:4]), 300, 10, 15)\n",
        "val_loader = DataLoader(periodic_dataset_val, 1, collate_fn=pad_collate)\n",
        "with torch.no_grad():\n",
        "  ncorrect = 0\n",
        "  nwrong = 0\n",
        "  for x, y, _, _ in val_loader:\n",
        "    predict = model(x.to(device)).argmax(1)\n",
        "    if torch.equal(y.to(device), predict):\n",
        "      ncorrect += 1\n",
        "    else:\n",
        "      nwrong += 1\n",
        "print(f'{ncorrect}, {nwrong}')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a', 'b', 'c', 'd']\n",
            "267, 33\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}